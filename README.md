# ğŸš€ AI Speed Benchmark CLI

A comprehensive, modern CLI tool for benchmarking AI models across multiple providers with **parallel execution**, **professional tables**, **arrow key navigation**, and **advanced metrics**.

## ğŸš€ Quick Start

```bash
git clone https://github.com/aptdnfapt/Ai-speedometer
# Install dependencies
npm install
# Start the CLI
npm run cli
```

## ğŸ® Usage Examples

### Main Menu (Modern Arrow Navigation)
```
ğŸš€ AI Speed Benchmark CLI
=============================

Use â†‘â†“ arrows to navigate, ENTER to select
Navigation is circular

â— Set Model
â—‹ Run Benchmark  
â—‹ Exit
```

### Model Selection (Circle-Based UI)
```
ğŸ¯ Select Models for Benchmark

Use â†‘â†“ arrows to navigate, SPACE to select/deselect, ENTER to confirm
Navigation is circular - moving past bottom/top wraps around
Press "A" to select all models, "N" to deselect all
Circle states: â—=Current+Selected  â—‹=Current+Unselected  â—=Selected  â—‹=Unselected

Available Models:
â— gpt-4 (OpenAI)
â—‹ claude-3-sonnet (Anthropic)

Selected: 1 models
```

### Provider Management (Vertical Stacking)
```
ğŸ“‹ Available Providers

1. chutes (openai-compatible)
   Models:
     1. zai-org/GLM-4.5-turbo
     2. deepseek-ai/DeepSeek-V3.1-turbo

2. zai (openai-compatible)
   Models:
     1. glm-4.5

3. zai-anthropic (anthropic)
   Models:
     1. claude-3-sonnet-20240229
```

### Benchmark Results (Professional Tables + Enhanced Charts)
```
ğŸ“Š BENCHMARK RESULTS
=========================

ğŸ“ˆ COMPREHENSIVE PERFORMANCE SUMMARY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model                  â”‚ Provider            â”‚ Total Time(s)   â”‚ TTFT(s)    â”‚ Tokens/Sec     â”‚ Output Tokens   â”‚ Prompt Tokens   â”‚ Total Tokens    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ zai-org/GLM-4.5-turbo  â”‚ chutes              â”‚ 11.47           â”‚ 1.00       â”‚ 81.5           â”‚ 935             â”‚ 14              â”‚ 1205            â”‚
â”‚ deepseek-ai/DeepSeek-V3 â”‚ chutes              â”‚ 5.21            â”‚ 0.83       â”‚ 178.6          â”‚ 930             â”‚ 14              â”‚ 742             â”‚
â”‚ glm-4.5                â”‚ zai                 â”‚ 11.30           â”‚ 5.30       â”‚ 72.9           â”‚ 824             â”‚ 14              â”‚ 1087            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š PERFORMANCE COMPARISON CHARTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â±ï¸  TOTAL TIME COMPARISON (lower is better)
   5.21s |     178.6 tok/s | deepseek-ai/DeepSeek-V3.1-turbo | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  11.30s |      72.9 tok/s | glm-4.5                                | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
  11.47s |      81.5 tok/s | zai-org/GLM-4.5-turbo                   | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

âš¡ TOKENS PER SECOND COMPARISON (higher is better)
     178.6 tok/s |    5.21s | deepseek-ai/DeepSeek-V3.1-turbo | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
      81.5 tok/s |   11.47s | zai-org/GLM-4.5-turbo                   | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
      72.9 tok/s |   11.30s | glm-4.5                                | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

ğŸ‰ Benchmark completed!
```

## ğŸ”§ Configuration

### Adding Providers (Arrow Key Navigation)

#### OpenAI-Compatible Providers
```
â• Add New Provider

Use â†‘â†“ arrows to navigate, ENTER to select
Navigation is circular

Select provider type:

â— OpenAI Compatible
â—‹ Anthropic
â—‹ Back to main menu
```

#### Anthropic Providers (Now Supports baseUrl)
```
Enter provider name (e.g., MyAnthropic):
Enter base URL (e.g., https://api.anthropic.com):
Enter Anthropic API key: [your-key]
Enter model name (e.g., claude-3-sonnet-20240229):
```


## âš¡ Performance Metrics Explained

### Core Metrics
- **Total Time**: Complete request duration (seconds)
- **Time to First Token (TTFT)**: Latency until first streaming token arrives
- **Tokens per Second**: Real-time throughput calculation
- **Output Tokens**: Number of tokens in the AI response
- **Prompt Tokens**: Number of tokens in the input prompt
- **Total Tokens**: Combined prompt + output tokens

### Chart Features
- **Dual Comparison Charts**: Both time and performance perspectives
- **Left-Side Metrics**: Shows actual values alongside bar charts
- **Color Coding**: Red bars for time (lower is better), green for performance (higher is better)
- **Dynamic Scaling**: Bars scale proportionally to the best/worst performers

## ğŸ› ï¸ Tech Stack

- **AI SDK**: Vercel AI SDK with streaming support ( opencode uses it too)
- **Table Rendering**: `cli-table3` for professional tables
- **Providers**: OpenAI-compatible and Anthropic APIs with custom baseUrl support
- **Navigation**: Circular arrow key navigation throughout
- **Colors**: ANSI escape codes for terminal styling
- **Configuration**: JSON-based persistent storage
- **Security**: .gitignore protection for sensitive files

## ğŸ¯ Requirements

- Node.js 18+
- API keys for AI providers
- Terminal that supports ANSI colors and arrow keys
- Git (for security configuration)


## ğŸ“ Advanced Features

### Parallel Execution
- **Speed**: Runs all selected models simultaneously
- **Efficiency**: No sequential waiting between models
- **Results**: Comprehensive comparison across all models

### Advanced Navigation
- **Universal Pattern**: All menus use the same arrow key navigation
- **Circular Movement**: Navigation wraps at top/bottom for seamless UX
- **Visual Feedback**: Clear indicators for current selections
- **Keyboard Shortcuts**: Quick actions like select all ('A') and deselect all ('N')

### Professional Output
- **Table Format**: Clean, aligned columns with proper spacing
- **Color Coding**: Different colors for different metric types
- **Comprehensive Data**: All relevant metrics in one view
- **Visual Charts**: Bar charts for quick visual comparison

